"""
SERVI√áO DE LLM (Large Language Model)
Gerencia a gera√ß√£o de respostas usando OpenAI GPT
"""

from openai import OpenAI
import os
import re
from typing import Tuple


class LLMService:
    """
    Servi√ßo para interagir com a LLM (OpenAI GPT)

    Respons√°vel por gerar respostas baseadas no contexto recuperado
    """

    def __init__(self):
        """
        Inicializa o servi√ßo de LLM

        Nota: Requer a vari√°vel de ambiente OPENAI_API_KEY
        """

        # Obt√©m a API key do ambiente
        api_key = os.getenv("OPENAI_API_KEY")

        if not api_key:
            print("\n" + "=" * 70)
            print("‚ö†Ô∏è  MODO RAG SEM IA ATIVADO")
            print("=" * 70)
            print("OPENAI_API_KEY n√£o encontrada.")
            print(
                "O sistema funcionar√° normalmente usando RAG (Recupera√ß√£o de Contexto),"
            )
            print("mas sem gera√ß√£o de texto por IA.")
            print(
                "\nVoc√™ ainda receber√° respostas √∫teis baseadas no conte√∫do dos PDFs!"
            )
            print("=" * 70 + "\n")
            self.client = None
        else:
            print("‚úÖ OpenAI configurada - Respostas com IA ativadas")
            try:
                self.client = OpenAI(api_key=api_key)
            except Exception as e:
                print(f"‚ùå Erro ao inicializar OpenAI: {e}")
                print("üîÑ Usando modo RAG sem IA")
                self.client = None

    def generate_answer(
        self,
        question: str,
        context: str,
        temperature: float = 0.7,
        max_tokens: int = 500,
    ) -> Tuple[str, int]:
        """
        Gera uma resposta usando a LLM com o contexto fornecido

        Args:
            question: Pergunta do usu√°rio
            context: Contexto recuperado do vector store
            temperature: Controla a criatividade (0=determin√≠stico, 2=criativo)
            max_tokens: N√∫mero m√°ximo de tokens na resposta

        Returns:
            Tupla contendo (resposta, tokens_usados)
        """

        # Se n√£o h√° cliente OpenAI, retorna resposta mock
        if not self.client:
            return self._generate_mock_answer(question, context), 0

        # Monta o prompt para a LLM
        system_prompt = """Voc√™ √© um assistente especializado em responder perguntas baseado em documentos.

INSTRU√á√ïES IMPORTANTES:
1. Use APENAS as informa√ß√µes fornecidas no contexto para responder
2. Se a resposta n√£o estiver no contexto, diga "N√£o encontrei essa informa√ß√£o no documento"
3. Seja preciso e objetivo
4. Cite trechos relevantes quando apropriado
5. N√£o invente informa√ß√µes (evite alucina√ß√µes)

CONFIGURA√á√ïES DE ALUCINA√á√ÉO:
- Temperature: {temperature} (quanto menor, mais factual e determin√≠stico)
- Sempre baseie suas respostas no contexto fornecido
- Se n√£o tiver certeza, expresse isso claramente
"""

        user_prompt = f"""CONTEXTO DO DOCUMENTO:
{context}

PERGUNTA DO USU√ÅRIO:
{question}

RESPOSTA:"""

        try:
            # Chama a API da OpenAI
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",  # Modelo mais econ√¥mico
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt.format(temperature=temperature),
                    },
                    {"role": "user", "content": user_prompt},
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=0.9,  # Nucleus sampling para reduzir alucina√ß√µes
                frequency_penalty=0.3,  # Reduz repeti√ß√µes
                presence_penalty=0.3,  # Incentiva novos t√≥picos
            )

            # Extrai a resposta
            answer = response.choices[0].message.content
            tokens_used = response.usage.total_tokens

            return answer, tokens_used

        except Exception as e:
            error_msg = str(e)
            print(f"‚ùå Erro ao chamar OpenAI: {error_msg}")

            # Detecta erros espec√≠ficos
            if "429" in error_msg or "quota" in error_msg.lower():
                print("üí° Cota da OpenAI excedida - Usando modo RAG sem IA")
            elif "401" in error_msg or "authentication" in error_msg.lower():
                print("üí° Erro de autentica√ß√£o - Usando modo RAG sem IA")
            else:
                print("üí° Erro na API OpenAI - Usando modo RAG sem IA")

            # Retorna resposta usando apenas o contexto recuperado
            return self._generate_mock_answer(question, context), 0

    def _generate_mock_answer(self, question: str, context: str) -> str:
        """
        Gera uma resposta usando apenas o contexto recuperado (RAG sem IA)

        Args:
            question: Pergunta do usu√°rio
            context: Contexto do documento

        Returns:
            Resposta formatada baseada no contexto
        """
        # Limpa caracteres especiais do PDF
        clean_context = self._clean_pdf_text(context)

        # Divide o contexto em par√°grafos
        paragraphs = [p.strip() for p in clean_context.split("\n") if p.strip()]

        # Monta uma resposta formatada e leg√≠vel
        response = f"""üìÑ RESPOSTA BASEADA NO DOCUMENTO (Modo RAG)

**Sua pergunta:** {question}

**Informa√ß√µes encontradas no documento:**

"""

        # Adiciona os par√°grafos mais relevantes (at√© 1200 caracteres)
        char_count = 0
        max_chars = 1200

        for para in paragraphs:
            if char_count + len(para) > max_chars:
                break
            response += f"{para}\n\n"
            char_count += len(para)

        if char_count >= max_chars:
            response += "...\n\n"

        response += """---
üí° **Nota:** Esta resposta mostra diretamente o conte√∫do recuperado do documento.
   Para respostas sintetizadas por IA, adicione cr√©ditos √† sua conta OpenAI.
"""

        return response

    def _clean_pdf_text(self, text: str) -> str:
        """
        Limpa texto extra√≠do de PDFs removendo caracteres especiais

        Args:
            text: Texto a ser limpo

        Returns:
            Texto limpo e formatado
        """
        if not text:
            return ""

        # Remove caracteres CID (comuns em PDFs)
        text = re.sub(r"\(cid:\d+\)", "‚Ä¢", text)

        # Remove m√∫ltiplos espa√ßos
        text = re.sub(r" +", " ", text)

        # Remove m√∫ltiplas quebras de linha (mant√©m no m√°ximo 2)
        text = re.sub(r"\n{3,}", "\n\n", text)

        return text.strip()
